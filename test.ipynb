{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model\\model.ckpt\n",
      "Tensor(\"logits_eval:0\", shape=(?, 5), dtype=float32)\n",
      "[[ 13.567807   -3.6067247   2.9480975  -7.6485505  -6.658281 ]\n",
      " [ -6.471053   11.616253   -3.6437724  -7.403587   -2.1361136]\n",
      " [ -6.895006   -8.251003   19.64625   -13.329626    9.398162 ]\n",
      " [ -4.5452924   0.6525191  -3.325743    7.955768   -7.8973804]\n",
      " [-11.246075  -16.601582   13.731161   -9.659376   25.85981  ]]\n",
      "[0 1 2 3 4]\n",
      "[0 1 2 3 4]\n",
      "(5,)\n",
      "flower 1 prediction:dasiy\n",
      "flower 2 prediction:dandelion\n",
      "flower 3 prediction:roses\n",
      "flower 4 prediction:sunflowers\n",
      "flower 5 prediction:tulips\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8\n",
    "\n",
    "from skimage import io,transform    \n",
    "import glob \n",
    "import os   \n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "path='flower_photos/'  # 数据存放路径 \n",
    "model_path='Model/model.ckpt'  # 模型保存路径\n",
    "# 从原始数据集的每个类别中各自随机抽取一张图像进行模型验证\n",
    "path1 = \"flower_photos/daisy/19813618946_93818db7aa_m.jpg\"\n",
    "path2 = \"flower_photos/dandelion/15987457_49dc11bf4b.jpg\"\n",
    "path3 = \"flower_photos/roses/2677417735_a697052d2d_n.jpg\"\n",
    "path4 = \"flower_photos/sunflowers/164670455_29d8e02bbd_n.jpg\"\n",
    "path5 = \"flower_photos/tulips/3991423020_9aaf2b5974_n.jpg\" \n",
    "\n",
    "# 定义花类字典，对每种花都赋值一个数值类别\n",
    "flower_dict = {0:'dasiy',1:'dandelion',2:'roses',3:'sunflowers',4:'tulips'} \n",
    "\n",
    "# 定义转换之后测试花类图像的大小（长宽高分别是100,100,3）\n",
    "w=100\n",
    "h=100\n",
    "c=3\n",
    "\n",
    "# 定义read_one_image函数，用于将验证图像转换成统一大小的格式（100*100*3）\n",
    "def read_one_image(path):               # 定义函数read_one_image\n",
    "    img = io.imread(path)               # 利用io.imread函数读取图像 \n",
    "    img = transform.resize(img,(w,h))   # 利用transform.resize函数对读取的图像数据进行格式统一化处理 \n",
    "    return np.asarray(img)              # 对img图像数据进行转化 \n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:              # 创建会话，用于执行已经定义的运算\n",
    "    data = []                           # 定义空白列表，用于保存处理后的验证数据 \n",
    "    data1 = read_one_image(path1)       # 利用自定义函数read_one_image依次对5张验证图像进行格式标准化处理\n",
    "    data2 = read_one_image(path2)\n",
    "    data3 = read_one_image(path3)\n",
    "    data4 = read_one_image(path4)\n",
    "    data5 = read_one_image(path5)\n",
    "    data.append(data1)                  # 将处理过后的验证图像数据保存在前面创建的空白data列表当中\n",
    "    data.append(data2)\n",
    "    data.append(data3)    \n",
    "    data.append(data4)\n",
    "    data.append(data5)\n",
    "\n",
    "    saver = tf.train.import_meta_graph('Model/model.ckpt.meta')     # 利用import_meta_graph函数直接加载之前已经持久化了的模型内容\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('Model'))         # 利用restore函数加载已经训练好的模型，并利用tf.train.latest_checkpoint函数提取最近一次保存的模型\n",
    "\n",
    "    graph = tf.get_default_graph()              # 获取当前的默认计算图 \n",
    "\n",
    "    x = graph.get_tensor_by_name(\"x:0\")         # 返回给定名称的tensor\n",
    "    # print(x)                                  # 返回加载的模型的参数 \n",
    "\n",
    "    feed_dict = {x:data}                        # 利用feed_dict，给占位符传输数据 \n",
    "\n",
    "    logits = graph.get_tensor_by_name(\"logits_eval:0\")      # 返回logits_eval对应的tensor\n",
    "    print(logits)\n",
    "\n",
    "    classification_result = sess.run(logits,feed_dict)      # 利用feed_dict把数据传输到logits进行验证图像预测\n",
    "\n",
    "    print(classification_result)                            # 打印预测矩阵\n",
    "    print(tf.argmax(classification_result,1).eval())        # 打印预测矩阵每一行的最大值的下标 \n",
    "\n",
    "    output = []                                             # 定义空白列表output\n",
    "    output = tf.argmax(classification_result,1).eval()      # 选择出预测矩阵每一行最大值的下标，并将字符串str当成有效的表达式来求值并返回计算结果，将其赋值给output\n",
    "    print(output)\n",
    "    print(output.shape)\n",
    "\n",
    "    for i in range(len(output)):                            # 遍历len(output)=5的花的类型\n",
    "        print(\"flower\",i+1,\"prediction:\"+flower_dict[output[i]])    # 输出每种花预测值最高的选项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
